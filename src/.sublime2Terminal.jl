


#========================================================================================

Compute the principal eigenvector and eigenvalue of ğ”¸
By definition, it is the one associated with a positive eigenvector.
In particular, it must be real.

B = -ğ”¸ is a Z matrix (all off diagonal are negative). Therefore, there exists a positive s such that sI + A has all positive entries. Applying Perron Frobenus, there a unique largest eigenvalue for sI + A, which is real, and the correspongind eigenctor is strictly positive.
Note that, in particular, it is the eigenvalue with largest real part, which means that I can look for the eigenvalue with largest real part 



If, moreover, B, is a M-matrix, then all its eigenvalues have positive real part. Therefore, all the eigenvalues of A have negative real part. Therefore, the eigenvalue with largest real part is also the eigenvalue with smallest magnitude.

========================================================================================#
function principal_eigenvalue(ğ”¸::AbstractMatrix; which = :SM, eigenvector = :right, r0 = ones(size(ğ”¸, 1)))
    l, Î·, r = nothing, nothing, nothing
    if which == :SM
        vals, vecs = Arpack.eigs(adjoint(ğ”¸); nev = 1, which = :SM)
        Î· = vals[1]
        l = vecs[:, 1]
        if eigenvector âˆˆ (:right, :both)
                vals, vecs = Arpack.eigs(ğ”¸; v0 = r0, nev = 1, which = :SM)
                Î· = vals[1]
                r = vecs[:, 1]
        end
    elseif which == :LR
        # Arpack LR tends to fail if the LR is close to zero, which is the typical case if we want to compute tail index
        # Arpack SM is much faster, but it does not always give the right eigenvector (either because LR â‰  SM (happens when the eigenvalue is very positive)
        # Even when it gives the right eigenvalue, it can return a complex eigenvector
        vals, vecs, info = KrylovKit.eigsolve(adjoint(ğ”¸), r0, 1, :LR, maxiter = size(ğ”¸, 1))
        info.converged == 0 &&  @warn "KrylovKit did not converge"
        Î· = vals[1]
        l = vecs[1]
        if eigenvector âˆˆ (:right, :both)
            vals, vecs, info = KrylovKit.eigsolve(ğ”¸, 1, :LR, maxiter = size(ğ”¸, 1))
            info.converged == 0 &&  @warn "KrylovKit did not converge"
            Î· = vals[1]
            r = vecs[1]
        end
    end
    l = clean_eigenvector_left(l)
    return l, clean_eigenvalue(Î·), clean_eigenvector_right(l, r)
end

clean_eigenvalue(Î·::Union{Nothing, Real}) = Î·
function clean_eigenvalue(Î·::Complex)
    if abs(imag(Î·) .>= eps())
        @warn "Principal Eigenvalue has some imaginary part $(Î·)"
    end
    real(Î·)
end

clean_eigenvector_left(::Nothing) = nothing
clean_eigenvector_left(l::AbstractVector) = abs.(l) ./ sum(abs.(l))


# correct normalization is \int r l = 1
clean_eigenvector_right(l, ::Nothing) = nothing
clean_eigenvector_right(l, r::AbstractVector) = abs.(r) ./ sum(l .* abs.(r))






# f is a function that for each Î¾ gives the generator matrix
# find_root return Î¶ such that the principal eigenvalue of f(Î¶) is zero
function find_root(f::Function; which = :SM, xatol = 1e-2, verbose = false, r0 = ones(size(f(1.0), 1)), kwargs...)
    out = 0.0
    if which == :SM
        try
            # SM is so much faster. So try if it works.
            f = Î¾ -> begin
                out = principal_eigenvalue(f(Î¾); which = :SM, r0 = r0)
                eltype(out[3]) <: Float64 && copyto!(r0, out[3])
                verbose && @show (:SM, Î¾, out[2])
                return out[2]
            end
            D = Î¾ -> FiniteDiff.finite_difference_derivative(f, Î¾)
            out = find_zero((f, D), 1.0, Roots.Newton(); xatol = xatol, kwargs...)
            out2 = principal_eigenvalue(f(out); which = :LR, r0 = r0)[2]
            if abs(out2) > 1e-2 
                @warn "Algorithm looking for SM eigenvalue = 0 converged to Î¶ = $out. However, the :LR eigenvalue for this Î¶ is  $out2"
                throw("there is an error")
            end
        catch
            which = :LR
        end
    end
    if which == :LR
        f = Î¾ -> begin
            out = principal_eigenvalue(f(Î¾); which = :LR, r0 = r0)
            eltype(out[3]) <: Float64 && copyto!(r0, out[3])
            verbose && @show (:LR, Î¾, out[2])
            return out[2]
        end
        D = Î¾ -> FiniteDiff.finite_difference_derivative(f, Î¾)
        try
            out = find_zero((f, D), 1.0, Roots.Newton(); xatol = xatol, kwargs...)
        catch
            out = find_zero((f, D), (1e-2, 10.0); xatol = xatol, kwargs...)
        end
    end
    return out
end

##############################################################################
##
## Feynman Kac
##
##############################################################################

"""
With direction = :backward
Solve the PDE backward in time
u(x, T) = Ïˆ(x)
0 = u_t + ğ”¸u_t - V(x, t)u +  f(x, t)


With direction = :forward
Solve the PDE forward in time
u(x, 0) = Ïˆ(x)
u_t = ğ”¸u - V(x)u + f(x)
"""
function feynman_kac(ğ”¸::AbstractMatrix; 
    t::AbstractVector = range(0, 100, step = 1/12), 
    Ïˆ::AbstractVector = ones(size(ğ”¸, 1)), 
    f::Union{AbstractVector, AbstractMatrix} = zeros(size(ğ”¸, 1)), 
    V::Union{AbstractVector, AbstractMatrix} = zeros(size(ğ”¸, 1)),
    direction= :backward)
    if direction == :backward
        u = zeros(size(ğ”¸, 1), length(t))
        u[:, end] = Ïˆ
        if isa(f, AbstractVector) && isa(V, AbstractVector)
            if isa(t, AbstractRange)
                dt = step(t)
                ğ”¹ = factorize(I + (Diagonal(V) - ğ”¸) * dt)
                for i in (length(t)-1):(-1):1
                    Ïˆ = ldiv!(ğ”¹, u[:, i+1] .+ f .* dt)
                    u[:, i] = Ïˆ
                end
            else
                for i in (length(t)-1):(-1):1
                    dt = t[i+1] - t[i]
                    ğ”¹ = I + (Diagonal(V) - ğ”¸) * dt
                    u[:, i] = ğ”¹ \ (u[:, i+1] .+ f .* dt)
                end
            end
        elseif isa(f, AbstractMatrix) && isa(V, AbstractMatrix)
            for i in (length(t)-1):(-1):1
                dt = t[i+1] - t[i]
                ğ”¹ = I + (Diagonal(view(V, :, i)) - ğ”¸) * dt
                u[:, i] = ğ”¹ \ (u[:, i+1] .+ f[:, i] .* dt)
            end
        else
            error("f and V must be Vectors or Matrices")
        end
        return u
    elseif direction == :forward
        u = feynman_kac(ğ”¸; t = - reverse(t), Ïˆ = Ïˆ, f = f, V = V, direction = :backward)
        return u[:,end:-1:1]
    else
        error("Direction must be :backward or :forward")
    end
end

